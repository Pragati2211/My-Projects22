{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc11a72f",
   "metadata": {},
   "source": [
    "## MATH2319/ MATH2387 Machine Learning\n",
    "#### Semester 1, 2022\n",
    "### Take-Home Machine Learning Assessment - Q2\n",
    "### Pragati Patidar (S3858702)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d55915",
   "metadata": {},
   "source": [
    "## Q2\n",
    "* Build a simple decision tree with depth 1 using this dataset for predicting the price (categorical) target feature using the Entropy split criterion.\n",
    "* Decision Trees (DTs) are a non-parametric supervised learning method used for classification and regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4ecf42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required packages\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None) \n",
    "from io import StringIO\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e416ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the automobile data from local repository\n",
    "df=pd.read_csv(\"THA_diamonds.csv\")\n",
    "seed=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ae5bd92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>depth</th>\n",
       "      <th>price</th>\n",
       "      <th>carat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Good</td>\n",
       "      <td>D</td>\n",
       "      <td>63.4</td>\n",
       "      <td>low</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Fair</td>\n",
       "      <td>I</td>\n",
       "      <td>64.4</td>\n",
       "      <td>low</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>Fair</td>\n",
       "      <td>D</td>\n",
       "      <td>57.5</td>\n",
       "      <td>premium</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Good</td>\n",
       "      <td>F</td>\n",
       "      <td>62.8</td>\n",
       "      <td>low</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Good</td>\n",
       "      <td>F</td>\n",
       "      <td>58.8</td>\n",
       "      <td>low</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Fair</td>\n",
       "      <td>F</td>\n",
       "      <td>59.6</td>\n",
       "      <td>low</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Fair</td>\n",
       "      <td>F</td>\n",
       "      <td>61.1</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Good</td>\n",
       "      <td>I</td>\n",
       "      <td>62.4</td>\n",
       "      <td>high</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Fair</td>\n",
       "      <td>F</td>\n",
       "      <td>64.6</td>\n",
       "      <td>low</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Good</td>\n",
       "      <td>I</td>\n",
       "      <td>63.3</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cut color  depth    price  carat\n",
       "63   Good     D   63.4      low   0.50\n",
       "92   Fair     I   64.4      low   0.70\n",
       "208  Fair     D   57.5  premium   0.90\n",
       "49   Good     F   62.8      low   0.55\n",
       "90   Good     F   58.8      low   0.60\n",
       "79   Fair     F   59.6      low   0.32\n",
       "157  Fair     F   61.1   medium   0.74\n",
       "177  Good     I   62.4     high   0.90\n",
       "18   Fair     F   64.6      low   0.50\n",
       "99   Good     I   63.3   medium   0.72"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#displaying 10 random observations from the Automobile dataset \n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51f3a56",
   "metadata": {},
   "source": [
    "### Part A\n",
    "The dataset for this question has 2 numerical descriptive features, carat and depth.\n",
    "\n",
    "Discretize these 2 features separately as \"category_1\", \"category_2\", and \"category_3\" respectively using the equal-frequency binning technique.\n",
    "Display the first 10 rows of the entire set of descriptive features after discretization of these two features.\n",
    "After this discretization, all features in your dataset will be categorical (which we will assume to be \"nominal categorical\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0e9d19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretizing varibale cut into three levels :'small', 'medium', 'high'\n",
    "df = df.copy()\n",
    "df['carat'] = pd.qcut(df['carat'], \n",
    "                              q=3, \n",
    "                              labels=['small', 'medium', 'high'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0810382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretizing varibale cut into three levels :'catagory1', 'catagory2', 'catagory3'\n",
    "df = df.copy()\n",
    "df['depth'] = pd.qcut(df['depth'], \n",
    "                              q=3, \n",
    "                              labels=['catagory1', 'catagory2', 'catagory3'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b97d7fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>depth</th>\n",
       "      <th>price</th>\n",
       "      <th>carat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good</td>\n",
       "      <td>D</td>\n",
       "      <td>catagory2</td>\n",
       "      <td>low</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fair</td>\n",
       "      <td>F</td>\n",
       "      <td>catagory3</td>\n",
       "      <td>low</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good</td>\n",
       "      <td>I</td>\n",
       "      <td>catagory1</td>\n",
       "      <td>low</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good</td>\n",
       "      <td>F</td>\n",
       "      <td>catagory1</td>\n",
       "      <td>low</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fair</td>\n",
       "      <td>F</td>\n",
       "      <td>catagory3</td>\n",
       "      <td>low</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fair</td>\n",
       "      <td>F</td>\n",
       "      <td>catagory3</td>\n",
       "      <td>low</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Good</td>\n",
       "      <td>D</td>\n",
       "      <td>catagory2</td>\n",
       "      <td>low</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Good</td>\n",
       "      <td>D</td>\n",
       "      <td>catagory2</td>\n",
       "      <td>low</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Good</td>\n",
       "      <td>D</td>\n",
       "      <td>catagory2</td>\n",
       "      <td>low</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fair</td>\n",
       "      <td>F</td>\n",
       "      <td>catagory3</td>\n",
       "      <td>low</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cut color      depth price  carat\n",
       "0  Good     D  catagory2   low  small\n",
       "1  Fair     F  catagory3   low  small\n",
       "2  Good     I  catagory1   low  small\n",
       "3  Good     F  catagory1   low  small\n",
       "4  Fair     F  catagory3   low  small\n",
       "5  Fair     F  catagory3   low  small\n",
       "6  Good     D  catagory2   low  small\n",
       "7  Good     D  catagory2   low  small\n",
       "8  Good     D  catagory2   low  small\n",
       "9  Fair     F  catagory3   low  small"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10 rows of the df:\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d7b9d4",
   "metadata": {},
   "source": [
    "###  Part B \n",
    "Compute the impurity of the price target feature.\n",
    "Let's calculate the entropy for the parent node and see how much uncertainty the tree can reduce by splitting on Balance.\n",
    "\n",
    "* The idea with entropy is that the more heterogenous and impure a feature is, the higher the entropy. Conversely, the more homogenous and pure a feature is, the lower the entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9801e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function using the fomula of entropy\n",
    "def compute_impurity(feature, impurity_criterion):\n",
    "    \"\"\"\n",
    "    This function calculates impurity of a feature.\n",
    "    Supported impurity criteria: 'entropy','gini'\n",
    "    input: feature (this needs to be a Pandas series)\n",
    "    output: feature impurity\n",
    "    \"\"\"\n",
    "    probs = feature.value_counts(normalize=True)\n",
    "    \n",
    "    if impurity_criterion == 'entropy':\n",
    "        impurity = -1 * np.sum(np.log2(probs) * probs)\n",
    "    elif impurity_criterion == 'gini':\n",
    "        impurity = 1 - np.sum(np.square(probs))\n",
    "    else:\n",
    "        raise ValueError('Unknown impurity criterion')\n",
    "        \n",
    "    return(round(impurity, 3))                        \n",
    "       \n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bf053c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.716"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the function in target variable price:\n",
    "target_entropy = compute_impurity(df['price'], 'entropy')\n",
    "target_entropy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4430d3a5",
   "metadata": {},
   "source": [
    "Entropy of the target variable price 1.716."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3da4d7d",
   "metadata": {},
   "source": [
    "###  Part c\n",
    "* Determining the root node for your decision tree.\n",
    "* The Root Node is the node that starts the graph. In a normal decision tree it evaluates the variable that best splits the data. Intermediate nodes: These are nodes where variables are evaluated but which are not the final nodes where predictions are made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc55171b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level name: small\n",
      "corresponding data partition:\n",
      "     cut color      depth price  carat\n",
      "0   Good     D  catagory2   low  small\n",
      "1   Fair     F  catagory3   low  small\n",
      "2   Good     I  catagory1   low  small\n",
      "3   Good     F  catagory1   low  small\n",
      "4   Fair     F  catagory3   low  small\n",
      "..   ...   ...        ...   ...    ...\n",
      "79  Fair     F  catagory1   low  small\n",
      "80  Good     D  catagory2   low  small\n",
      "81  Good     F  catagory3   low  small\n",
      "83  Good     D  catagory2   low  small\n",
      "86  Good     D  catagory1   low  small\n",
      "\n",
      "[71 rows x 5 columns]\n",
      "partition target feature impurity: -0.0\n",
      "partition weight: 71/212\n",
      "====================\n",
      "level name: medium\n",
      "corresponding data partition:\n",
      "      cut color      depth    price   carat\n",
      "11   Good     I  catagory2      low  medium\n",
      "15   Good     I  catagory2      low  medium\n",
      "16   Good     I  catagory2      low  medium\n",
      "27   Fair     I  catagory1      low  medium\n",
      "34   Fair     I  catagory1      low  medium\n",
      "..    ...   ...        ...      ...     ...\n",
      "172  Good     D  catagory1     high  medium\n",
      "173  Good     D  catagory2     high  medium\n",
      "174  Good     D  catagory3     high  medium\n",
      "175  Good     D  catagory3     high  medium\n",
      "198  Good     D  catagory1  premium  medium\n",
      "\n",
      "[79 rows x 5 columns]\n",
      "partition target feature impurity: 1.365\n",
      "partition weight: 79/212\n",
      "====================\n",
      "level name: high\n",
      "corresponding data partition:\n",
      "      cut color      depth    price carat\n",
      "99   Good     I  catagory2   medium  high\n",
      "103  Good     I  catagory2   medium  high\n",
      "105  Good     I  catagory1   medium  high\n",
      "119  Fair     I  catagory3   medium  high\n",
      "124  Fair     I  catagory3   medium  high\n",
      "..    ...   ...        ...      ...   ...\n",
      "207  Good     F  catagory2  premium  high\n",
      "208  Fair     D  catagory1  premium  high\n",
      "209  Fair     F  catagory3  premium  high\n",
      "210  Good     I  catagory1  premium  high\n",
      "211  Fair     F  catagory1  premium  high\n",
      "\n",
      "[62 rows x 5 columns]\n",
      "partition target feature impurity: 1.529\n",
      "partition weight: 62/212\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "#Let's see how the partitions look like for this feature and \n",
    "# what the corresponding calculations are using the entropy split criterion.\n",
    "for level in df['carat'].unique():\n",
    "    print('level name:', level)\n",
    "    df_feature_level = df[df['carat'] == level]\n",
    "    print('corresponding data partition:')\n",
    "    print(df_feature_level)\n",
    "    print('partition target feature impurity:', compute_impurity(df_feature_level['price'], 'entropy'))\n",
    "    print('partition weight:', str(len(df_feature_level)) + '/' + str(len(df)))\n",
    "    print('====================')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348c237a",
   "metadata": {},
   "source": [
    "##### we define a function called compute_impurity() that calculates impurity of a feature using either entropy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30b41267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function for calculating _information_gain:\n",
    "\n",
    "def comp_feature_information_gain(df, target, descriptive_feature, split_criterion):\n",
    "    \"\"\"\n",
    "    This function calculates information gain for splitting on \n",
    "    a particular descriptive feature for a given dataset\n",
    "    and a given impurity criteria.\n",
    "    Supported split criterion: 'entropy'\n",
    "    \"\"\"\n",
    "    \n",
    "    print('target feature:', target)\n",
    "    print('descriptive_feature:', descriptive_feature)\n",
    "    print('split criterion:', split_criterion)\n",
    "            \n",
    "    target_entropy = compute_impurity(df[target], split_criterion)\n",
    "\n",
    "    # we define two lists below:\n",
    "    # entropy_list to store the entropy of each partition\n",
    "    # weight_list to store the relative number of observations in each partition\n",
    "    entropy_list = list()\n",
    "    weight_list = list()\n",
    "    \n",
    "    # loop over each level of the descriptive feature\n",
    "    # to partition the dataset with respect to that level\n",
    "    # and compute the entropy and the weight of the level's partition\n",
    "    for level in df[descriptive_feature].unique():\n",
    "        df_feature_level = df[df[descriptive_feature] == level]\n",
    "        entropy_level = compute_impurity(df_feature_level[target], split_criterion)\n",
    "        entropy_list.append(round(entropy_level, 3))\n",
    "        weight_level = len(df_feature_level) / len(df)\n",
    "        weight_list.append(round(weight_level, 3))\n",
    "\n",
    "    print('impurity of partitions:', entropy_list)\n",
    "    print('weights of partitions:', weight_list)\n",
    "\n",
    "    feature_remaining_impurity = np.sum(np.array(entropy_list) * np.array(weight_list))\n",
    "    print('remaining impurity:', feature_remaining_impurity)\n",
    "    \n",
    "    information_gain = target_entropy - feature_remaining_impurity\n",
    "    print('information gain:', information_gain)\n",
    "    \n",
    "    print('====================')\n",
    "\n",
    "    return(information_gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14b43e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target feature: price\n",
      "descriptive_feature: cut\n",
      "split criterion: entropy\n",
      "impurity of partitions: [1.68, 1.78]\n",
      "weights of partitions: [0.717, 0.283]\n",
      "remaining impurity: 1.7083\n",
      "information gain: 0.00770000000000004\n",
      "====================\n",
      "target feature: price\n",
      "descriptive_feature: color\n",
      "split criterion: entropy\n",
      "impurity of partitions: [1.657, 1.445, 1.833]\n",
      "weights of partitions: [0.269, 0.434, 0.297]\n",
      "remaining impurity: 1.617264\n",
      "information gain: 0.09873599999999993\n",
      "====================\n",
      "target feature: price\n",
      "descriptive_feature: depth\n",
      "split criterion: entropy\n",
      "impurity of partitions: [1.517, 1.749, 1.74]\n",
      "weights of partitions: [0.349, 0.316, 0.335]\n",
      "remaining impurity: 1.6650170000000002\n",
      "information gain: 0.05098299999999978\n",
      "====================\n",
      "target feature: price\n",
      "descriptive_feature: carat\n",
      "split criterion: entropy\n",
      "impurity of partitions: [-0.0, 1.365, 1.529]\n",
      "weights of partitions: [0.335, 0.373, 0.292]\n",
      "remaining impurity: 0.9556129999999998\n",
      "information gain: 0.7603870000000001\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "#Now that our function has been defined, we will call it for each descriptive feature in the dataset.\n",
    "#First let's call it using the entropy split criteria.\n",
    "\n",
    "split_criterion = 'entropy'\n",
    "for feature in df.drop(columns='price').columns:\n",
    "    feature_info_gain = comp_feature_information_gain(df, 'price', feature, split_criterion)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f1d2b8",
   "metadata": {},
   "source": [
    "We observe that, with the entropy split criteria, the highest information gain occurs with the \"color\" feature.\n",
    "\n",
    "This is the for the split at the root node of the corresponding decision tree. In subsequent splits, the above procedure is repeated with the subset of the entire dataset in the current branch until the termination condition is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722a238d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inserting data into table:\n",
    "#feature price:\n",
    "df_splits = pd.DataFrame(columns=['split','remainder', 'info_gain','is_optimal'])\n",
    "df_splits.loc[len(df_splits)]=['color',1.6173,  0.0987, False]\n",
    "df_splits.loc[len(df_splits)]= ['cut',1.7083, 0.0987,False]\n",
    "df_splits.loc[len(df_splits)]= ['depth',1.6650,0.05098, False]\n",
    "df_splits.loc[len(df_splits)]= ['carat',1.7083, 0.76038,False]\n",
    "#\n",
    "df_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caad2c9e",
   "metadata": {},
   "source": [
    "### Pard D:\n",
    "Assuming the carat descriptive feature is at the root node\n",
    "(NOTE: This feature may or may not be the optimal root node, but you will just assume it is). \n",
    "Under this assumption, you will make predictions for the price target variable.\n",
    "*  calculationg the probability by hand for price- low, medium, high, premium.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f684674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how the partitions look like for this feature and \n",
    "# what the corresponding calculations are using the entropy split criterion.\n",
    "for level in df['carat'].unique():\n",
    "    low=0\n",
    "    medium=0\n",
    "    high=0\n",
    "    premium=0\n",
    "    print('level name:', level)\n",
    "    df_feature_level = df[df['carat'] == level]\n",
    "    print('corresponding data partition:')\n",
    "    print(df_feature_level)\n",
    "    \n",
    "for value in df['price']:\n",
    "    if value == 'low':\n",
    "        low += 1\n",
    "    elif value== 'medium':\n",
    "        medium += 1\n",
    "    elif value ==' high':\n",
    "        high += 1\n",
    "    else:\n",
    "        premium += 1\n",
    "            \n",
    "    \n",
    "    print('partition target feature impurity:', compute_impurity(df_feature_level['price'], 'entropy'))\n",
    "    print('partition weight:', str(len(df_feature_level)) + '/' + str(len(df)))\n",
    "    print('price_probability: low', low/(len(df_feature_level)))\n",
    "    print('price_probability: medium', medium/(len(df_feature_level)))\n",
    "    print('price_probability: high', high/(len(df_feature_level)))\n",
    "    print('price_probability: premium', premium/(len(df_feature_level)))\n",
    "    print('====================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b8b638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inserting data into table:\n",
    "#feature price, root node carat:\n",
    "df_pred = pd.DataFrame(columns=['leaf_condition','low_price_prob', 'medium_price_prob','high_price_prob', \n",
    "                                'premium_price', 'leaf_pridiction'])\n",
    "df_pred.loc[len(df_pred)]=['carat==small', 1.0,0.0,0.0,0.0,'low']\n",
    "df_pred.loc[len(df_pred)]=['carat== medium', 0.28 ,0.69,0.10,0.01,'medium']\n",
    "df_pred.loc[len(df_pred)]=['carat==large', 0.0,0.42,0.37,0.21,'large']\n",
    "df_pred\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
